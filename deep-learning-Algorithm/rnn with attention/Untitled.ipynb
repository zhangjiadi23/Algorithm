{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 22683.16it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nXoh: one-hot version of X, the \"1\" entry\\'s index is mapped to the character thanks to human_vocab. Xoh.shape = (m, Tx, len(human_vocab))\\nYoh: one-hot version of Y, the \"1\" entry\\'s index is mapped to the character thanks to machine_vocab. Yoh.shape = (m, Tx, len(machine_vocab)). Here, len(machine_vocab) = 11 since there are 11 characters (\\'-\\' as well as 0-9).\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx = 30\n",
    "ty = 10\n",
    "x, y, xoh, yoh = preprocess_data(dataset, human_vocab, machine_vocab, tx, ty)\n",
    "'''\n",
    "Xoh: one-hot version of X, the \"1\" entry's index is mapped to the character thanks to human_vocab. Xoh.shape = (m, Tx, len(human_vocab))\n",
    "Yoh: one-hot version of Y, the \"1\" entry's index is mapped to the character thanks to machine_vocab. Yoh.shape = (m, Tx, len(machine_vocab)). Here, len(machine_vocab) = 11 since there are 11 characters ('-' as well as 0-9).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeator = RepeatVector(tx)\n",
    "concatenator  = Concatenate(axis = -1)\n",
    "densor1 = Dense(10, activation = 'tanh')\n",
    "densor2 = Dense(1, activation = 'relu')\n",
    "activator = Activation(softmax, name = 'attention_weights')\n",
    "dotor = Dot(axes= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    s_prev = repeator(s_prev)\n",
    "    concat = concatenator([a, s_prev])\n",
    "    e = densor1(concat)\n",
    "    energies = densor2(e)\n",
    "    alphas = activator(energies)\n",
    "    context = dotor([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_a = 32\n",
    "n_s = 64\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state=True)\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(tx, ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    X = Input(shape = (tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s, ), name='s0')\n",
    "    c0 = Input(shape=(n_s, ), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n",
    "    \n",
    "    for t in range(ty):\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state=[s, c])\n",
    "        \n",
    "        out = output_layer(s)\n",
    "        \n",
    "        outputs.append(out)\n",
    "        \n",
    "    model = Model(inputs = [X, s0, c0], outputs = outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = model(tx,ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 37)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 64)       17920       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 30, 64)       0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 128)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[7][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[8][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[9][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30, 10)       1290        concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 concatenate_1[7][0]              \n",
      "                                                                 concatenate_1[8][0]              \n",
      "                                                                 concatenate_1[9][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30, 1)        11          dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "                                                                 dense_2[5][0]                    \n",
      "                                                                 dense_2[6][0]                    \n",
      "                                                                 dense_2[7][0]                    \n",
      "                                                                 dense_2[8][0]                    \n",
      "                                                                 dense_2[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  33024       dot_1[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[4][2]                     \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[5][2]                     \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[6][2]                     \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[7][2]                     \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[8][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           715         lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[9][0]                     \n",
      "==================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr = 0.005, beta_1 = 0.9, beta_2 = 0.999,decay = 0.01)  \n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt,metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2800/10000 [=======>......................] - ETA: 9:40 - loss: 23.9797 - dense_3_loss: 2.3984 - dense_3_acc: 0.0100 - dense_3_acc_1: 0.4200 - dense_3_acc_2: 0.1300 - dense_3_acc_3: 0.1000 - dense_3_acc_4: 0.1100 - dense_3_acc_5: 0.0200 - dense_3_acc_6: 0.0600 - dense_3_acc_7: 0.0600 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.090 - ETA: 4:51 - loss: 23.8178 - dense_3_loss: 2.4017 - dense_3_acc: 0.0050 - dense_3_acc_1: 0.2100 - dense_3_acc_2: 0.0650 - dense_3_acc_3: 0.0500 - dense_3_acc_4: 0.5500 - dense_3_acc_5: 0.0150 - dense_3_acc_6: 0.0300 - dense_3_acc_7: 0.5200 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.045 - ETA: 3:14 - loss: 23.6374 - dense_3_loss: 2.4176 - dense_3_acc: 0.0033 - dense_3_acc_1: 0.1400 - dense_3_acc_2: 0.0433 - dense_3_acc_3: 0.0333 - dense_3_acc_4: 0.7000 - dense_3_acc_5: 0.0100 - dense_3_acc_6: 0.0200 - dense_3_acc_7: 0.6800 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.030 - ETA: 2:26 - loss: 23.4099 - dense_3_loss: 2.4359 - dense_3_acc: 0.0025 - dense_3_acc_1: 0.1050 - dense_3_acc_2: 0.0325 - dense_3_acc_3: 0.0250 - dense_3_acc_4: 0.7750 - dense_3_acc_5: 0.0075 - dense_3_acc_6: 0.0150 - dense_3_acc_7: 0.7600 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.022 - ETA: 1:57 - loss: 23.1804 - dense_3_loss: 2.4892 - dense_3_acc: 0.0020 - dense_3_acc_1: 0.0840 - dense_3_acc_2: 0.0260 - dense_3_acc_3: 0.0200 - dense_3_acc_4: 0.8200 - dense_3_acc_5: 0.0060 - dense_3_acc_6: 0.0120 - dense_3_acc_7: 0.8080 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.018 - ETA: 1:37 - loss: 22.9896 - dense_3_loss: 2.6147 - dense_3_acc: 0.0017 - dense_3_acc_1: 0.0700 - dense_3_acc_2: 0.0217 - dense_3_acc_3: 0.0167 - dense_3_acc_4: 0.8500 - dense_3_acc_5: 0.0050 - dense_3_acc_6: 0.0100 - dense_3_acc_7: 0.8400 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.015 - ETA: 1:24 - loss: 22.8560 - dense_3_loss: 2.7092 - dense_3_acc: 0.0014 - dense_3_acc_1: 0.0600 - dense_3_acc_2: 0.0186 - dense_3_acc_3: 0.0143 - dense_3_acc_4: 0.8714 - dense_3_acc_5: 0.0043 - dense_3_acc_6: 0.0086 - dense_3_acc_7: 0.8629 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.012 - ETA: 1:13 - loss: 22.6984 - dense_3_loss: 2.7634 - dense_3_acc: 0.0012 - dense_3_acc_1: 0.1150 - dense_3_acc_2: 0.0487 - dense_3_acc_3: 0.0225 - dense_3_acc_4: 0.8863 - dense_3_acc_5: 0.0037 - dense_3_acc_6: 0.0075 - dense_3_acc_7: 0.8800 - dense_3_acc_8: 0.0000e+00 - dense_3_acc_9: 0.011 - ETA: 1:05 - loss: 22.5633 - dense_3_loss: 2.7859 - dense_3_acc: 0.0011 - dense_3_acc_1: 0.1444 - dense_3_acc_2: 0.0667 - dense_3_acc_3: 0.0367 - dense_3_acc_4: 0.7878 - dense_3_acc_5: 0.0922 - dense_3_acc_6: 0.0122 - dense_3_acc_7: 0.7867 - dense_3_acc_8: 0.0189 - dense_3_acc_9: 0.0244    - ETA: 58s - loss: 22.4197 - dense_3_loss: 2.7903 - dense_3_acc: 1.0000e-03 - dense_3_acc_1: 0.1720 - dense_3_acc_2: 0.0790 - dense_3_acc_3: 0.0450 - dense_3_acc_4: 0.7090 - dense_3_acc_5: 0.1490 - dense_3_acc_6: 0.0340 - dense_3_acc_7: 0.7080 - dense_3_acc_8: 0.0510 - dense_3_acc_9: 0.03 - ETA: 53s - loss: 22.3346 - dense_3_loss: 2.8012 - dense_3_acc: 9.0909e-04 - dense_3_acc_1: 0.1964 - dense_3_acc_2: 0.0973 - dense_3_acc_3: 0.0491 - dense_3_acc_4: 0.7291 - dense_3_acc_5: 0.1355 - dense_3_acc_6: 0.0409 - dense_3_acc_7: 0.6436 - dense_3_acc_8: 0.0764 - dense_3_acc_9: 0.03 - ETA: 49s - loss: 22.2536 - dense_3_loss: 2.8106 - dense_3_acc: 8.3333e-04 - dense_3_acc_1: 0.2075 - dense_3_acc_2: 0.1083 - dense_3_acc_3: 0.0492 - dense_3_acc_4: 0.7517 - dense_3_acc_5: 0.1242 - dense_3_acc_6: 0.0375 - dense_3_acc_7: 0.6733 - dense_3_acc_8: 0.0700 - dense_3_acc_9: 0.03 - ETA: 45s - loss: 22.1665 - dense_3_loss: 2.8030 - dense_3_acc: 7.6923e-04 - dense_3_acc_1: 0.2192 - dense_3_acc_2: 0.1177 - dense_3_acc_3: 0.0454 - dense_3_acc_4: 0.7708 - dense_3_acc_5: 0.1146 - dense_3_acc_6: 0.0346 - dense_3_acc_7: 0.6985 - dense_3_acc_8: 0.0646 - dense_3_acc_9: 0.03 - ETA: 42s - loss: 22.1050 - dense_3_loss: 2.8042 - dense_3_acc: 7.1429e-04 - dense_3_acc_1: 0.2329 - dense_3_acc_2: 0.1271 - dense_3_acc_3: 0.0421 - dense_3_acc_4: 0.7871 - dense_3_acc_5: 0.1064 - dense_3_acc_6: 0.0321 - dense_3_acc_7: 0.7200 - dense_3_acc_8: 0.0600 - dense_3_acc_9: 0.02 - ETA: 39s - loss: 22.0434 - dense_3_loss: 2.8070 - dense_3_acc: 6.6667e-04 - dense_3_acc_1: 0.2440 - dense_3_acc_2: 0.1340 - dense_3_acc_3: 0.0393 - dense_3_acc_4: 0.8013 - dense_3_acc_5: 0.0993 - dense_3_acc_6: 0.0300 - dense_3_acc_7: 0.7387 - dense_3_acc_8: 0.0560 - dense_3_acc_9: 0.02 - ETA: 36s - loss: 21.9737 - dense_3_loss: 2.8081 - dense_3_acc: 6.2500e-04 - dense_3_acc_1: 0.2519 - dense_3_acc_2: 0.1381 - dense_3_acc_3: 0.0413 - dense_3_acc_4: 0.8138 - dense_3_acc_5: 0.0931 - dense_3_acc_6: 0.0281 - dense_3_acc_7: 0.7550 - dense_3_acc_8: 0.0525 - dense_3_acc_9: 0.02 - ETA: 34s - loss: 21.9013 - dense_3_loss: 2.8032 - dense_3_acc: 5.8824e-04 - dense_3_acc_1: 0.2612 - dense_3_acc_2: 0.1435 - dense_3_acc_3: 0.0441 - dense_3_acc_4: 0.8247 - dense_3_acc_5: 0.0876 - dense_3_acc_6: 0.0265 - dense_3_acc_7: 0.7694 - dense_3_acc_8: 0.0494 - dense_3_acc_9: 0.02 - ETA: 32s - loss: 21.8313 - dense_3_loss: 2.8025 - dense_3_acc: 5.5556e-04 - dense_3_acc_1: 0.2672 - dense_3_acc_2: 0.1483 - dense_3_acc_3: 0.0494 - dense_3_acc_4: 0.8328 - dense_3_acc_5: 0.0828 - dense_3_acc_6: 0.0250 - dense_3_acc_7: 0.7822 - dense_3_acc_8: 0.0467 - dense_3_acc_9: 0.02 - ETA: 30s - loss: 21.7618 - dense_3_loss: 2.8027 - dense_3_acc: 5.2632e-04 - dense_3_acc_1: 0.2695 - dense_3_acc_2: 0.1526 - dense_3_acc_3: 0.0542 - dense_3_acc_4: 0.8274 - dense_3_acc_5: 0.0784 - dense_3_acc_6: 0.0237 - dense_3_acc_7: 0.7937 - dense_3_acc_8: 0.0442 - dense_3_acc_9: 0.02 - ETA: 29s - loss: 21.7116 - dense_3_loss: 2.8043 - dense_3_acc: 5.0000e-04 - dense_3_acc_1: 0.2755 - dense_3_acc_2: 0.1545 - dense_3_acc_3: 0.0600 - dense_3_acc_4: 0.8075 - dense_3_acc_5: 0.0745 - dense_3_acc_6: 0.0225 - dense_3_acc_7: 0.8040 - dense_3_acc_8: 0.0420 - dense_3_acc_9: 0.02 - ETA: 27s - loss: 21.6664 - dense_3_loss: 2.8023 - dense_3_acc: 4.7619e-04 - dense_3_acc_1: 0.2833 - dense_3_acc_2: 0.1543 - dense_3_acc_3: 0.0619 - dense_3_acc_4: 0.8029 - dense_3_acc_5: 0.0710 - dense_3_acc_6: 0.0214 - dense_3_acc_7: 0.8133 - dense_3_acc_8: 0.0400 - dense_3_acc_9: 0.01 - ETA: 26s - loss: 21.6105 - dense_3_loss: 2.8027 - dense_3_acc: 4.5455e-04 - dense_3_acc_1: 0.2977 - dense_3_acc_2: 0.1564 - dense_3_acc_3: 0.0655 - dense_3_acc_4: 0.8118 - dense_3_acc_5: 0.0677 - dense_3_acc_6: 0.0205 - dense_3_acc_7: 0.8218 - dense_3_acc_8: 0.0382 - dense_3_acc_9: 0.01 - ETA: 25s - loss: 21.5570 - dense_3_loss: 2.8044 - dense_3_acc: 4.3478e-04 - dense_3_acc_1: 0.3152 - dense_3_acc_2: 0.1578 - dense_3_acc_3: 0.0657 - dense_3_acc_4: 0.8200 - dense_3_acc_5: 0.0648 - dense_3_acc_6: 0.0196 - dense_3_acc_7: 0.8296 - dense_3_acc_8: 0.0365 - dense_3_acc_9: 0.01 - ETA: 24s - loss: 21.5032 - dense_3_loss: 2.7991 - dense_3_acc: 4.1667e-04 - dense_3_acc_1: 0.3250 - dense_3_acc_2: 0.1600 - dense_3_acc_3: 0.0679 - dense_3_acc_4: 0.8275 - dense_3_acc_5: 0.0621 - dense_3_acc_6: 0.0188 - dense_3_acc_7: 0.8367 - dense_3_acc_8: 0.0350 - dense_3_acc_9: 0.01 - ETA: 23s - loss: 21.4507 - dense_3_loss: 2.8078 - dense_3_acc: 4.0000e-04 - dense_3_acc_1: 0.3360 - dense_3_acc_2: 0.1652 - dense_3_acc_3: 0.0684 - dense_3_acc_4: 0.8344 - dense_3_acc_5: 0.0596 - dense_3_acc_6: 0.0180 - dense_3_acc_7: 0.8432 - dense_3_acc_8: 0.0336 - dense_3_acc_9: 0.01 - ETA: 22s - loss: 21.3987 - dense_3_loss: 2.8039 - dense_3_acc: 3.8462e-04 - dense_3_acc_1: 0.3488 - dense_3_acc_2: 0.1696 - dense_3_acc_3: 0.0681 - dense_3_acc_4: 0.8408 - dense_3_acc_5: 0.0573 - dense_3_acc_6: 0.0173 - dense_3_acc_7: 0.8492 - dense_3_acc_8: 0.0323 - dense_3_acc_9: 0.01 - ETA: 21s - loss: 21.3419 - dense_3_loss: 2.8033 - dense_3_acc: 3.7037e-04 - dense_3_acc_1: 0.3596 - dense_3_acc_2: 0.1730 - dense_3_acc_3: 0.0670 - dense_3_acc_4: 0.8467 - dense_3_acc_5: 0.0552 - dense_3_acc_6: 0.0167 - dense_3_acc_7: 0.8548 - dense_3_acc_8: 0.0311 - dense_3_acc_9: 0.01 - ETA: 20s - loss: 21.2965 - dense_3_loss: 2.8042 - dense_3_acc: 3.5714e-04 - dense_3_acc_1: 0.3696 - dense_3_acc_2: 0.1743 - dense_3_acc_3: 0.0646 - dense_3_acc_4: 0.8521 - dense_3_acc_5: 0.0532 - dense_3_acc_6: 0.0161 - dense_3_acc_7: 0.8600 - dense_3_acc_8: 0.0300 - dense_3_acc_9: 0.0168\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5700/10000 [================>.............] - ETA: 19s - loss: 21.2402 - dense_3_loss: 2.8051 - dense_3_acc: 3.4483e-04 - dense_3_acc_1: 0.3814 - dense_3_acc_2: 0.1745 - dense_3_acc_3: 0.0624 - dense_3_acc_4: 0.8572 - dense_3_acc_5: 0.0514 - dense_3_acc_6: 0.0155 - dense_3_acc_7: 0.8648 - dense_3_acc_8: 0.0290 - dense_3_acc_9: 0.01 - ETA: 18s - loss: 21.1933 - dense_3_loss: 2.8068 - dense_3_acc: 3.3333e-04 - dense_3_acc_1: 0.3893 - dense_3_acc_2: 0.1777 - dense_3_acc_3: 0.0603 - dense_3_acc_4: 0.8620 - dense_3_acc_5: 0.0497 - dense_3_acc_6: 0.0150 - dense_3_acc_7: 0.8693 - dense_3_acc_8: 0.0280 - dense_3_acc_9: 0.01 - ETA: 18s - loss: 21.1387 - dense_3_loss: 2.8019 - dense_3_acc: 3.2258e-04 - dense_3_acc_1: 0.3961 - dense_3_acc_2: 0.1794 - dense_3_acc_3: 0.0584 - dense_3_acc_4: 0.8665 - dense_3_acc_5: 0.0481 - dense_3_acc_6: 0.0145 - dense_3_acc_7: 0.8735 - dense_3_acc_8: 0.0271 - dense_3_acc_9: 0.01 - ETA: 17s - loss: 21.0859 - dense_3_loss: 2.8027 - dense_3_acc: 3.1250e-04 - dense_3_acc_1: 0.4047 - dense_3_acc_2: 0.1791 - dense_3_acc_3: 0.0566 - dense_3_acc_4: 0.8706 - dense_3_acc_5: 0.0466 - dense_3_acc_6: 0.0141 - dense_3_acc_7: 0.8756 - dense_3_acc_8: 0.0372 - dense_3_acc_9: 0.01 - ETA: 16s - loss: 21.0433 - dense_3_loss: 2.8040 - dense_3_acc: 3.0303e-04 - dense_3_acc_1: 0.4106 - dense_3_acc_2: 0.1830 - dense_3_acc_3: 0.0548 - dense_3_acc_4: 0.8745 - dense_3_acc_5: 0.0452 - dense_3_acc_6: 0.0136 - dense_3_acc_7: 0.8500 - dense_3_acc_8: 0.0448 - dense_3_acc_9: 0.02 - ETA: 16s - loss: 20.9937 - dense_3_loss: 2.8029 - dense_3_acc: 2.9412e-04 - dense_3_acc_1: 0.4171 - dense_3_acc_2: 0.1865 - dense_3_acc_3: 0.0535 - dense_3_acc_4: 0.8782 - dense_3_acc_5: 0.0438 - dense_3_acc_6: 0.0132 - dense_3_acc_7: 0.8291 - dense_3_acc_8: 0.0553 - dense_3_acc_9: 0.02 - ETA: 15s - loss: 20.9291 - dense_3_loss: 2.7969 - dense_3_acc: 2.8571e-04 - dense_3_acc_1: 0.4237 - dense_3_acc_2: 0.1889 - dense_3_acc_3: 0.0554 - dense_3_acc_4: 0.8817 - dense_3_acc_5: 0.0426 - dense_3_acc_6: 0.0129 - dense_3_acc_7: 0.8286 - dense_3_acc_8: 0.0606 - dense_3_acc_9: 0.02 - ETA: 15s - loss: 20.8756 - dense_3_loss: 2.7934 - dense_3_acc: 2.7778e-04 - dense_3_acc_1: 0.4306 - dense_3_acc_2: 0.1928 - dense_3_acc_3: 0.0569 - dense_3_acc_4: 0.8850 - dense_3_acc_5: 0.0414 - dense_3_acc_6: 0.0125 - dense_3_acc_7: 0.8333 - dense_3_acc_8: 0.0589 - dense_3_acc_9: 0.02 - ETA: 14s - loss: 20.8296 - dense_3_loss: 2.7935 - dense_3_acc: 0.0146 - dense_3_acc_1: 0.4365 - dense_3_acc_2: 0.1970 - dense_3_acc_3: 0.0581 - dense_3_acc_4: 0.8881 - dense_3_acc_5: 0.0403 - dense_3_acc_6: 0.0122 - dense_3_acc_7: 0.8378 - dense_3_acc_8: 0.0573 - dense_3_acc_9: 0.0286   - ETA: 14s - loss: 20.7844 - dense_3_loss: 2.7935 - dense_3_acc: 0.0316 - dense_3_acc_1: 0.4424 - dense_3_acc_2: 0.1989 - dense_3_acc_3: 0.0566 - dense_3_acc_4: 0.8911 - dense_3_acc_5: 0.0392 - dense_3_acc_6: 0.0118 - dense_3_acc_7: 0.8421 - dense_3_acc_8: 0.0597 - dense_3_acc_9: 0.03 - ETA: 13s - loss: 20.7359 - dense_3_loss: 2.7902 - dense_3_acc: 0.0469 - dense_3_acc_1: 0.4472 - dense_3_acc_2: 0.2005 - dense_3_acc_3: 0.0551 - dense_3_acc_4: 0.8938 - dense_3_acc_5: 0.0382 - dense_3_acc_6: 0.0115 - dense_3_acc_7: 0.8462 - dense_3_acc_8: 0.0664 - dense_3_acc_9: 0.03 - ETA: 13s - loss: 20.6837 - dense_3_loss: 2.7845 - dense_3_acc: 0.0602 - dense_3_acc_1: 0.4505 - dense_3_acc_2: 0.2033 - dense_3_acc_3: 0.0545 - dense_3_acc_4: 0.8965 - dense_3_acc_5: 0.0373 - dense_3_acc_6: 0.0113 - dense_3_acc_7: 0.8358 - dense_3_acc_8: 0.0765 - dense_3_acc_9: 0.03 - ETA: 12s - loss: 20.6336 - dense_3_loss: 2.7807 - dense_3_acc: 0.0741 - dense_3_acc_1: 0.4549 - dense_3_acc_2: 0.2068 - dense_3_acc_3: 0.0551 - dense_3_acc_4: 0.8990 - dense_3_acc_5: 0.0363 - dense_3_acc_6: 0.0112 - dense_3_acc_7: 0.8232 - dense_3_acc_8: 0.0817 - dense_3_acc_9: 0.03 - ETA: 12s - loss: 20.5816 - dense_3_loss: 2.7791 - dense_3_acc: 0.0890 - dense_3_acc_1: 0.4607 - dense_3_acc_2: 0.2088 - dense_3_acc_3: 0.0562 - dense_3_acc_4: 0.9014 - dense_3_acc_5: 0.0355 - dense_3_acc_6: 0.0110 - dense_3_acc_7: 0.8221 - dense_3_acc_8: 0.0869 - dense_3_acc_9: 0.04 - ETA: 12s - loss: 20.5303 - dense_3_loss: 2.7791 - dense_3_acc: 0.1033 - dense_3_acc_1: 0.4663 - dense_3_acc_2: 0.2105 - dense_3_acc_3: 0.0551 - dense_3_acc_4: 0.9037 - dense_3_acc_5: 0.0347 - dense_3_acc_6: 0.0107 - dense_3_acc_7: 0.8223 - dense_3_acc_8: 0.0886 - dense_3_acc_9: 0.04 - ETA: 11s - loss: 20.4761 - dense_3_loss: 2.7792 - dense_3_acc: 0.1159 - dense_3_acc_1: 0.4707 - dense_3_acc_2: 0.2127 - dense_3_acc_3: 0.0539 - dense_3_acc_4: 0.9059 - dense_3_acc_5: 0.0339 - dense_3_acc_6: 0.0105 - dense_3_acc_7: 0.8239 - dense_3_acc_8: 0.0877 - dense_3_acc_9: 0.04 - ETA: 11s - loss: 20.4278 - dense_3_loss: 2.7794 - dense_3_acc: 0.1269 - dense_3_acc_1: 0.4738 - dense_3_acc_2: 0.2169 - dense_3_acc_3: 0.0527 - dense_3_acc_4: 0.9080 - dense_3_acc_5: 0.0331 - dense_3_acc_6: 0.0102 - dense_3_acc_7: 0.8273 - dense_3_acc_8: 0.0909 - dense_3_acc_9: 0.04 - ETA: 10s - loss: 20.3812 - dense_3_loss: 2.7801 - dense_3_acc: 0.1385 - dense_3_acc_1: 0.4778 - dense_3_acc_2: 0.2176 - dense_3_acc_3: 0.0515 - dense_3_acc_4: 0.9100 - dense_3_acc_5: 0.0324 - dense_3_acc_6: 0.0100 - dense_3_acc_7: 0.8309 - dense_3_acc_8: 0.0935 - dense_3_acc_9: 0.04 - ETA: 10s - loss: 20.3332 - dense_3_loss: 2.7805 - dense_3_acc: 0.1485 - dense_3_acc_1: 0.4806 - dense_3_acc_2: 0.2194 - dense_3_acc_3: 0.0517 - dense_3_acc_4: 0.9119 - dense_3_acc_5: 0.0321 - dense_3_acc_6: 0.0100 - dense_3_acc_7: 0.8223 - dense_3_acc_8: 0.0962 - dense_3_acc_9: 0.04 - ETA: 10s - loss: 20.2811 - dense_3_loss: 2.7814 - dense_3_acc: 0.1588 - dense_3_acc_1: 0.4840 - dense_3_acc_2: 0.2204 - dense_3_acc_3: 0.0517 - dense_3_acc_4: 0.9138 - dense_3_acc_5: 0.0329 - dense_3_acc_6: 0.0098 - dense_3_acc_7: 0.8208 - dense_3_acc_8: 0.1021 - dense_3_acc_9: 0.05 - ETA: 9s - loss: 20.2287 - dense_3_loss: 2.7822 - dense_3_acc: 0.1682 - dense_3_acc_1: 0.4867 - dense_3_acc_2: 0.2233 - dense_3_acc_3: 0.0506 - dense_3_acc_4: 0.9155 - dense_3_acc_5: 0.0324 - dense_3_acc_6: 0.0096 - dense_3_acc_7: 0.8231 - dense_3_acc_8: 0.1092 - dense_3_acc_9: 0.0520 - ETA: 9s - loss: 20.1761 - dense_3_loss: 2.7809 - dense_3_acc: 0.1778 - dense_3_acc_1: 0.4900 - dense_3_acc_2: 0.2238 - dense_3_acc_3: 0.0512 - dense_3_acc_4: 0.9172 - dense_3_acc_5: 0.0318 - dense_3_acc_6: 0.0094 - dense_3_acc_7: 0.8266 - dense_3_acc_8: 0.1142 - dense_3_acc_9: 0.053 - ETA: 9s - loss: 20.1337 - dense_3_loss: 2.7824 - dense_3_acc: 0.1855 - dense_3_acc_1: 0.4916 - dense_3_acc_2: 0.2245 - dense_3_acc_3: 0.0529 - dense_3_acc_4: 0.9188 - dense_3_acc_5: 0.0314 - dense_3_acc_6: 0.0092 - dense_3_acc_7: 0.8298 - dense_3_acc_8: 0.1122 - dense_3_acc_9: 0.054 - ETA: 8s - loss: 20.0838 - dense_3_loss: 2.7828 - dense_3_acc: 0.1944 - dense_3_acc_1: 0.4946 - dense_3_acc_2: 0.2260 - dense_3_acc_3: 0.0537 - dense_3_acc_4: 0.9204 - dense_3_acc_5: 0.0335 - dense_3_acc_6: 0.0094 - dense_3_acc_7: 0.8325 - dense_3_acc_8: 0.1100 - dense_3_acc_9: 0.055 - ETA: 8s - loss: 20.0339 - dense_3_loss: 2.7834 - dense_3_acc: 0.2028 - dense_3_acc_1: 0.4974 - dense_3_acc_2: 0.2289 - dense_3_acc_3: 0.0538 - dense_3_acc_4: 0.9219 - dense_3_acc_5: 0.0374 - dense_3_acc_6: 0.0092 - dense_3_acc_7: 0.8355 - dense_3_acc_8: 0.1083 - dense_3_acc_9: 0.055 - ETA: 8s - loss: 19.9805 - dense_3_loss: 2.7829 - dense_3_acc: 0.2102 - dense_3_acc_1: 0.4993 - dense_3_acc_2: 0.2319 - dense_3_acc_3: 0.0556 - dense_3_acc_4: 0.9233 - dense_3_acc_5: 0.0385 - dense_3_acc_6: 0.0091 - dense_3_acc_7: 0.8385 - dense_3_acc_8: 0.1072 - dense_3_acc_9: 0.057 - ETA: 8s - loss: 19.9306 - dense_3_loss: 2.7817 - dense_3_acc: 0.2173 - dense_3_acc_1: 0.5011 - dense_3_acc_2: 0.2307 - dense_3_acc_3: 0.0571 - dense_3_acc_4: 0.9247 - dense_3_acc_5: 0.0404 - dense_3_acc_6: 0.0089 - dense_3_acc_7: 0.8407 - dense_3_acc_8: 0.1080 - dense_3_acc_9: 0.057 - ETA: 7s - loss: 19.8786 - dense_3_loss: 2.7801 - dense_3_acc: 0.2227 - dense_3_acc_1: 0.5014 - dense_3_acc_2: 0.2332 - dense_3_acc_3: 0.0561 - dense_3_acc_4: 0.9261 - dense_3_acc_5: 0.0477 - dense_3_acc_6: 0.0089 - dense_3_acc_7: 0.8429 - dense_3_acc_8: 0.1143 - dense_3_acc_9: 0.058 - ETA: 7s - loss: 19.8261 - dense_3_loss: 2.7774 - dense_3_acc: 0.2293 - dense_3_acc_1: 0.5032 - dense_3_acc_2: 0.2360 - dense_3_acc_3: 0.0551 - dense_3_acc_4: 0.9274 - dense_3_acc_5: 0.0591 - dense_3_acc_6: 0.0089 - dense_3_acc_7: 0.8449 - dense_3_acc_8: 0.1193 - dense_3_acc_9: 0.0596"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8600/10000 [========================>.....] - ETA: 7s - loss: 19.7691 - dense_3_loss: 2.7760 - dense_3_acc: 0.2366 - dense_3_acc_1: 0.5057 - dense_3_acc_2: 0.2381 - dense_3_acc_3: 0.0559 - dense_3_acc_4: 0.9286 - dense_3_acc_5: 0.0697 - dense_3_acc_6: 0.0095 - dense_3_acc_7: 0.8467 - dense_3_acc_8: 0.1190 - dense_3_acc_9: 0.060 - ETA: 7s - loss: 19.7067 - dense_3_loss: 2.7724 - dense_3_acc: 0.2434 - dense_3_acc_1: 0.5081 - dense_3_acc_2: 0.2400 - dense_3_acc_3: 0.0569 - dense_3_acc_4: 0.9298 - dense_3_acc_5: 0.0771 - dense_3_acc_6: 0.0105 - dense_3_acc_7: 0.8490 - dense_3_acc_8: 0.1175 - dense_3_acc_9: 0.062 - ETA: 6s - loss: 19.6451 - dense_3_loss: 2.7695 - dense_3_acc: 0.2505 - dense_3_acc_1: 0.5118 - dense_3_acc_2: 0.2430 - dense_3_acc_3: 0.0560 - dense_3_acc_4: 0.9310 - dense_3_acc_5: 0.0893 - dense_3_acc_6: 0.0105 - dense_3_acc_7: 0.8515 - dense_3_acc_8: 0.1207 - dense_3_acc_9: 0.062 - ETA: 6s - loss: 19.5846 - dense_3_loss: 2.7682 - dense_3_acc: 0.2566 - dense_3_acc_1: 0.5148 - dense_3_acc_2: 0.2449 - dense_3_acc_3: 0.0551 - dense_3_acc_4: 0.9321 - dense_3_acc_5: 0.1005 - dense_3_acc_6: 0.0105 - dense_3_acc_7: 0.8539 - dense_3_acc_8: 0.1238 - dense_3_acc_9: 0.063 - ETA: 6s - loss: 19.5189 - dense_3_loss: 2.7642 - dense_3_acc: 0.2634 - dense_3_acc_1: 0.5174 - dense_3_acc_2: 0.2452 - dense_3_acc_3: 0.0563 - dense_3_acc_4: 0.9332 - dense_3_acc_5: 0.1074 - dense_3_acc_6: 0.0106 - dense_3_acc_7: 0.8563 - dense_3_acc_8: 0.1273 - dense_3_acc_9: 0.064 - ETA: 6s - loss: 19.4520 - dense_3_loss: 2.7612 - dense_3_acc: 0.2686 - dense_3_acc_1: 0.5202 - dense_3_acc_2: 0.2471 - dense_3_acc_3: 0.0562 - dense_3_acc_4: 0.9343 - dense_3_acc_5: 0.1170 - dense_3_acc_6: 0.0113 - dense_3_acc_7: 0.8586 - dense_3_acc_8: 0.1330 - dense_3_acc_9: 0.064 - ETA: 5s - loss: 19.3814 - dense_3_loss: 2.7563 - dense_3_acc: 0.2739 - dense_3_acc_1: 0.5231 - dense_3_acc_2: 0.2497 - dense_3_acc_3: 0.0553 - dense_3_acc_4: 0.9353 - dense_3_acc_5: 0.1267 - dense_3_acc_6: 0.0114 - dense_3_acc_7: 0.8608 - dense_3_acc_8: 0.1381 - dense_3_acc_9: 0.065 - ETA: 5s - loss: 19.3049 - dense_3_loss: 2.7517 - dense_3_acc: 0.2794 - dense_3_acc_1: 0.5265 - dense_3_acc_2: 0.2534 - dense_3_acc_3: 0.0560 - dense_3_acc_4: 0.9363 - dense_3_acc_5: 0.1363 - dense_3_acc_6: 0.0132 - dense_3_acc_7: 0.8629 - dense_3_acc_8: 0.1417 - dense_3_acc_9: 0.067 - ETA: 5s - loss: 19.2284 - dense_3_loss: 2.7481 - dense_3_acc: 0.2847 - dense_3_acc_1: 0.5295 - dense_3_acc_2: 0.2561 - dense_3_acc_3: 0.0571 - dense_3_acc_4: 0.9373 - dense_3_acc_5: 0.1461 - dense_3_acc_6: 0.0144 - dense_3_acc_7: 0.8650 - dense_3_acc_8: 0.1455 - dense_3_acc_9: 0.068 - ETA: 5s - loss: 19.1523 - dense_3_loss: 2.7436 - dense_3_acc: 0.2912 - dense_3_acc_1: 0.5333 - dense_3_acc_2: 0.2569 - dense_3_acc_3: 0.0570 - dense_3_acc_4: 0.9382 - dense_3_acc_5: 0.1561 - dense_3_acc_6: 0.0154 - dense_3_acc_7: 0.8670 - dense_3_acc_8: 0.1478 - dense_3_acc_9: 0.070 - ETA: 5s - loss: 19.0757 - dense_3_loss: 2.7383 - dense_3_acc: 0.2968 - dense_3_acc_1: 0.5374 - dense_3_acc_2: 0.2587 - dense_3_acc_3: 0.0563 - dense_3_acc_4: 0.9391 - dense_3_acc_5: 0.1659 - dense_3_acc_6: 0.0156 - dense_3_acc_7: 0.8690 - dense_3_acc_8: 0.1510 - dense_3_acc_9: 0.071 - ETA: 4s - loss: 18.9974 - dense_3_loss: 2.7333 - dense_3_acc: 0.3009 - dense_3_acc_1: 0.5393 - dense_3_acc_2: 0.2609 - dense_3_acc_3: 0.0567 - dense_3_acc_4: 0.9400 - dense_3_acc_5: 0.1749 - dense_3_acc_6: 0.0158 - dense_3_acc_7: 0.8709 - dense_3_acc_8: 0.1557 - dense_3_acc_9: 0.071 - ETA: 4s - loss: 18.9199 - dense_3_loss: 2.7287 - dense_3_acc: 0.3066 - dense_3_acc_1: 0.5417 - dense_3_acc_2: 0.2621 - dense_3_acc_3: 0.0576 - dense_3_acc_4: 0.9409 - dense_3_acc_5: 0.1844 - dense_3_acc_6: 0.0160 - dense_3_acc_7: 0.8727 - dense_3_acc_8: 0.1594 - dense_3_acc_9: 0.072 - ETA: 4s - loss: 18.8370 - dense_3_loss: 2.7241 - dense_3_acc: 0.3118 - dense_3_acc_1: 0.5452 - dense_3_acc_2: 0.2656 - dense_3_acc_3: 0.0586 - dense_3_acc_4: 0.9417 - dense_3_acc_5: 0.1935 - dense_3_acc_6: 0.0166 - dense_3_acc_7: 0.8745 - dense_3_acc_8: 0.1632 - dense_3_acc_9: 0.073 - ETA: 4s - loss: 18.7557 - dense_3_loss: 2.7189 - dense_3_acc: 0.3160 - dense_3_acc_1: 0.5492 - dense_3_acc_2: 0.2686 - dense_3_acc_3: 0.0589 - dense_3_acc_4: 0.9425 - dense_3_acc_5: 0.2018 - dense_3_acc_6: 0.0169 - dense_3_acc_7: 0.8762 - dense_3_acc_8: 0.1676 - dense_3_acc_9: 0.073 - ETA: 4s - loss: 18.6723 - dense_3_loss: 2.7129 - dense_3_acc: 0.3200 - dense_3_acc_1: 0.5511 - dense_3_acc_2: 0.2697 - dense_3_acc_3: 0.0597 - dense_3_acc_4: 0.9433 - dense_3_acc_5: 0.2095 - dense_3_acc_6: 0.0178 - dense_3_acc_7: 0.8779 - dense_3_acc_8: 0.1714 - dense_3_acc_9: 0.075 - ETA: 3s - loss: 18.5973 - dense_3_loss: 2.7078 - dense_3_acc: 0.3232 - dense_3_acc_1: 0.5522 - dense_3_acc_2: 0.2703 - dense_3_acc_3: 0.0604 - dense_3_acc_4: 0.9441 - dense_3_acc_5: 0.2165 - dense_3_acc_6: 0.0188 - dense_3_acc_7: 0.8796 - dense_3_acc_8: 0.1726 - dense_3_acc_9: 0.076 - ETA: 3s - loss: 18.5163 - dense_3_loss: 2.7031 - dense_3_acc: 0.3271 - dense_3_acc_1: 0.5544 - dense_3_acc_2: 0.2717 - dense_3_acc_3: 0.0612 - dense_3_acc_4: 0.9448 - dense_3_acc_5: 0.2241 - dense_3_acc_6: 0.0200 - dense_3_acc_7: 0.8812 - dense_3_acc_8: 0.1748 - dense_3_acc_9: 0.077 - ETA: 3s - loss: 18.4377 - dense_3_loss: 2.6979 - dense_3_acc: 0.3305 - dense_3_acc_1: 0.5575 - dense_3_acc_2: 0.2732 - dense_3_acc_3: 0.0621 - dense_3_acc_4: 0.9455 - dense_3_acc_5: 0.2311 - dense_3_acc_6: 0.0213 - dense_3_acc_7: 0.8828 - dense_3_acc_8: 0.1789 - dense_3_acc_9: 0.078 - ETA: 3s - loss: 18.3580 - dense_3_loss: 2.6931 - dense_3_acc: 0.3344 - dense_3_acc_1: 0.5603 - dense_3_acc_2: 0.2748 - dense_3_acc_3: 0.0632 - dense_3_acc_4: 0.9462 - dense_3_acc_5: 0.2384 - dense_3_acc_6: 0.0222 - dense_3_acc_7: 0.8843 - dense_3_acc_8: 0.1822 - dense_3_acc_9: 0.079 - ETA: 3s - loss: 18.2823 - dense_3_loss: 2.6887 - dense_3_acc: 0.3376 - dense_3_acc_1: 0.5624 - dense_3_acc_2: 0.2764 - dense_3_acc_3: 0.0636 - dense_3_acc_4: 0.9469 - dense_3_acc_5: 0.2447 - dense_3_acc_6: 0.0238 - dense_3_acc_7: 0.8858 - dense_3_acc_8: 0.1851 - dense_3_acc_9: 0.079 - ETA: 3s - loss: 18.2050 - dense_3_loss: 2.6840 - dense_3_acc: 0.3415 - dense_3_acc_1: 0.5651 - dense_3_acc_2: 0.2770 - dense_3_acc_3: 0.0648 - dense_3_acc_4: 0.9476 - dense_3_acc_5: 0.2509 - dense_3_acc_6: 0.0247 - dense_3_acc_7: 0.8872 - dense_3_acc_8: 0.1875 - dense_3_acc_9: 0.081 - ETA: 2s - loss: 18.1267 - dense_3_loss: 2.6798 - dense_3_acc: 0.3461 - dense_3_acc_1: 0.5684 - dense_3_acc_2: 0.2776 - dense_3_acc_3: 0.0661 - dense_3_acc_4: 0.9483 - dense_3_acc_5: 0.2579 - dense_3_acc_6: 0.0254 - dense_3_acc_7: 0.8886 - dense_3_acc_8: 0.1899 - dense_3_acc_9: 0.081 - ETA: 2s - loss: 18.0503 - dense_3_loss: 2.6754 - dense_3_acc: 0.3498 - dense_3_acc_1: 0.5716 - dense_3_acc_2: 0.2783 - dense_3_acc_3: 0.0674 - dense_3_acc_4: 0.9489 - dense_3_acc_5: 0.2641 - dense_3_acc_6: 0.0258 - dense_3_acc_7: 0.8900 - dense_3_acc_8: 0.1915 - dense_3_acc_9: 0.082 - ETA: 2s - loss: 17.9736 - dense_3_loss: 2.6707 - dense_3_acc: 0.3526 - dense_3_acc_1: 0.5743 - dense_3_acc_2: 0.2805 - dense_3_acc_3: 0.0679 - dense_3_acc_4: 0.9495 - dense_3_acc_5: 0.2710 - dense_3_acc_6: 0.0268 - dense_3_acc_7: 0.8913 - dense_3_acc_8: 0.1945 - dense_3_acc_9: 0.082 - ETA: 2s - loss: 17.8966 - dense_3_loss: 2.6665 - dense_3_acc: 0.3565 - dense_3_acc_1: 0.5776 - dense_3_acc_2: 0.2822 - dense_3_acc_3: 0.0687 - dense_3_acc_4: 0.9501 - dense_3_acc_5: 0.2761 - dense_3_acc_6: 0.0284 - dense_3_acc_7: 0.8927 - dense_3_acc_8: 0.1971 - dense_3_acc_9: 0.083 - ETA: 2s - loss: 17.8216 - dense_3_loss: 2.6622 - dense_3_acc: 0.3593 - dense_3_acc_1: 0.5806 - dense_3_acc_2: 0.2840 - dense_3_acc_3: 0.0693 - dense_3_acc_4: 0.9507 - dense_3_acc_5: 0.2821 - dense_3_acc_6: 0.0298 - dense_3_acc_7: 0.8939 - dense_3_acc_8: 0.1995 - dense_3_acc_9: 0.083 - ETA: 2s - loss: 17.7483 - dense_3_loss: 2.6578 - dense_3_acc: 0.3622 - dense_3_acc_1: 0.5846 - dense_3_acc_2: 0.2846 - dense_3_acc_3: 0.0701 - dense_3_acc_4: 0.9513 - dense_3_acc_5: 0.2882 - dense_3_acc_6: 0.0313 - dense_3_acc_7: 0.8952 - dense_3_acc_8: 0.2011 - dense_3_acc_9: 0.084 - ETA: 1s - loss: 17.6773 - dense_3_loss: 2.6530 - dense_3_acc: 0.3645 - dense_3_acc_1: 0.5880 - dense_3_acc_2: 0.2859 - dense_3_acc_3: 0.0709 - dense_3_acc_4: 0.9519 - dense_3_acc_5: 0.2936 - dense_3_acc_6: 0.0334 - dense_3_acc_7: 0.8964 - dense_3_acc_8: 0.2034 - dense_3_acc_9: 0.0853"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA: 1s - loss: 17.6046 - dense_3_loss: 2.6494 - dense_3_acc: 0.3675 - dense_3_acc_1: 0.5914 - dense_3_acc_2: 0.2878 - dense_3_acc_3: 0.0718 - dense_3_acc_4: 0.9524 - dense_3_acc_5: 0.3000 - dense_3_acc_6: 0.0344 - dense_3_acc_7: 0.8976 - dense_3_acc_8: 0.2054 - dense_3_acc_9: 0.087 - ETA: 1s - loss: 17.5361 - dense_3_loss: 2.6459 - dense_3_acc: 0.3709 - dense_3_acc_1: 0.5940 - dense_3_acc_2: 0.2885 - dense_3_acc_3: 0.0719 - dense_3_acc_4: 0.9530 - dense_3_acc_5: 0.3050 - dense_3_acc_6: 0.0364 - dense_3_acc_7: 0.8987 - dense_3_acc_8: 0.2073 - dense_3_acc_9: 0.087 - ETA: 1s - loss: 17.4681 - dense_3_loss: 2.6423 - dense_3_acc: 0.3734 - dense_3_acc_1: 0.5971 - dense_3_acc_2: 0.2901 - dense_3_acc_3: 0.0725 - dense_3_acc_4: 0.9535 - dense_3_acc_5: 0.3092 - dense_3_acc_6: 0.0397 - dense_3_acc_7: 0.8999 - dense_3_acc_8: 0.2087 - dense_3_acc_9: 0.088 - ETA: 1s - loss: 17.4008 - dense_3_loss: 2.6383 - dense_3_acc: 0.3764 - dense_3_acc_1: 0.6009 - dense_3_acc_2: 0.2924 - dense_3_acc_3: 0.0729 - dense_3_acc_4: 0.9540 - dense_3_acc_5: 0.3147 - dense_3_acc_6: 0.0402 - dense_3_acc_7: 0.9010 - dense_3_acc_8: 0.2102 - dense_3_acc_9: 0.088 - ETA: 1s - loss: 17.3323 - dense_3_loss: 2.6349 - dense_3_acc: 0.3789 - dense_3_acc_1: 0.6040 - dense_3_acc_2: 0.2945 - dense_3_acc_3: 0.0736 - dense_3_acc_4: 0.9545 - dense_3_acc_5: 0.3197 - dense_3_acc_6: 0.0421 - dense_3_acc_7: 0.9021 - dense_3_acc_8: 0.2133 - dense_3_acc_9: 0.089 - ETA: 1s - loss: 17.2652 - dense_3_loss: 2.6320 - dense_3_acc: 0.3818 - dense_3_acc_1: 0.6066 - dense_3_acc_2: 0.2959 - dense_3_acc_3: 0.0741 - dense_3_acc_4: 0.9550 - dense_3_acc_5: 0.3249 - dense_3_acc_6: 0.0439 - dense_3_acc_7: 0.9032 - dense_3_acc_8: 0.2160 - dense_3_acc_9: 0.090 - ETA: 0s - loss: 17.1983 - dense_3_loss: 2.6282 - dense_3_acc: 0.3846 - dense_3_acc_1: 0.6098 - dense_3_acc_2: 0.2975 - dense_3_acc_3: 0.0752 - dense_3_acc_4: 0.9555 - dense_3_acc_5: 0.3297 - dense_3_acc_6: 0.0470 - dense_3_acc_7: 0.9042 - dense_3_acc_8: 0.2182 - dense_3_acc_9: 0.090 - ETA: 0s - loss: 17.1323 - dense_3_loss: 2.6247 - dense_3_acc: 0.3872 - dense_3_acc_1: 0.6128 - dense_3_acc_2: 0.2987 - dense_3_acc_3: 0.0761 - dense_3_acc_4: 0.9560 - dense_3_acc_5: 0.3352 - dense_3_acc_6: 0.0489 - dense_3_acc_7: 0.9052 - dense_3_acc_8: 0.2205 - dense_3_acc_9: 0.090 - ETA: 0s - loss: 17.0648 - dense_3_loss: 2.6208 - dense_3_acc: 0.3900 - dense_3_acc_1: 0.6161 - dense_3_acc_2: 0.3007 - dense_3_acc_3: 0.0776 - dense_3_acc_4: 0.9564 - dense_3_acc_5: 0.3401 - dense_3_acc_6: 0.0513 - dense_3_acc_7: 0.9062 - dense_3_acc_8: 0.2227 - dense_3_acc_9: 0.091 - ETA: 0s - loss: 17.0011 - dense_3_loss: 2.6173 - dense_3_acc: 0.3921 - dense_3_acc_1: 0.6192 - dense_3_acc_2: 0.3023 - dense_3_acc_3: 0.0783 - dense_3_acc_4: 0.9569 - dense_3_acc_5: 0.3454 - dense_3_acc_6: 0.0529 - dense_3_acc_7: 0.9072 - dense_3_acc_8: 0.2249 - dense_3_acc_9: 0.092 - ETA: 0s - loss: 16.9373 - dense_3_loss: 2.6133 - dense_3_acc: 0.3938 - dense_3_acc_1: 0.6226 - dense_3_acc_2: 0.3038 - dense_3_acc_3: 0.0789 - dense_3_acc_4: 0.9573 - dense_3_acc_5: 0.3503 - dense_3_acc_6: 0.0552 - dense_3_acc_7: 0.9081 - dense_3_acc_8: 0.2266 - dense_3_acc_9: 0.093 - ETA: 0s - loss: 16.8739 - dense_3_loss: 2.6103 - dense_3_acc: 0.3967 - dense_3_acc_1: 0.6259 - dense_3_acc_2: 0.3052 - dense_3_acc_3: 0.0801 - dense_3_acc_4: 0.9578 - dense_3_acc_5: 0.3545 - dense_3_acc_6: 0.0572 - dense_3_acc_7: 0.9091 - dense_3_acc_8: 0.2279 - dense_3_acc_9: 0.094 - ETA: 0s - loss: 16.8105 - dense_3_loss: 2.6073 - dense_3_acc: 0.3993 - dense_3_acc_1: 0.6292 - dense_3_acc_2: 0.3071 - dense_3_acc_3: 0.0806 - dense_3_acc_4: 0.9582 - dense_3_acc_5: 0.3591 - dense_3_acc_6: 0.0588 - dense_3_acc_7: 0.9100 - dense_3_acc_8: 0.2291 - dense_3_acc_9: 0.094 - 13s 1ms/step - loss: 16.7456 - dense_3_loss: 2.6043 - dense_3_acc: 0.4020 - dense_3_acc_1: 0.6324 - dense_3_acc_2: 0.3095 - dense_3_acc_3: 0.0814 - dense_3_acc_4: 0.9586 - dense_3_acc_5: 0.3638 - dense_3_acc_6: 0.0606 - dense_3_acc_7: 0.9109 - dense_3_acc_8: 0.2306 - dense_3_acc_9: 0.0958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x234df7b9cc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([xoh, s0, c0], outputs, epochs=1, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 3 may 1979\n",
      "output: 1979-05-03\n",
      "source: 5 april 09\n",
      "output: 2009-05-05\n",
      "source: 21th of august 2016\n",
      "output: 2016-08-21\n",
      "source: tue 10 jul 2007\n",
      "output: 2007-07-10\n",
      "source: saturday may 9 2018\n",
      "output: 2018-05-09\n",
      "source: march 3 2001\n",
      "output: 2001-03-03\n",
      "source: march 3rd 2001\n",
      "output: 2001-03-03\n",
      "source: 1 march 2001\n",
      "output: 2001-03-01\n"
     ]
    }
   ],
   "source": [
    "examples = ['3 may 1979', '5 april 09', '21th of august 2016', 'tue 10 jul 2007', 'saturday may 9 2018', \n",
    "            'march 3 2001', 'march 3rd 2001', '1 march 2001']\n",
    "for example in examples:\n",
    "    source  = string_to_int(example, tx, human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source)))\n",
    "    source = source.reshape(1, 30,37)\n",
    "    prediction = model.predict([source, s0, c0])\n",
    "    prediction = np.argmax(prediction, axis=-1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    \n",
    "    print('source:', example)\n",
    "    print('output:', ''.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
