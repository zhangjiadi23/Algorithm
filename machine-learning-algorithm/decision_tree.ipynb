{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start.time = time.time()\n",
    "        logging.debug('start %s()' %func.__name__)\n",
    "        ret = func(*args, **kwargs)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logging.debug('end %s(), cost %s seconds' % (func.__name__, end_time-start_time))\n",
    "        \n",
    "        return ret\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binaryzation(img):\n",
    "    cv_img = img.astype(np.unit8)\n",
    "    cv2.threshold(cv_img, 50, 1, cv2.cv.CV_THRESH_BINARY_INV, cv_img)\n",
    "    return cv_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binaryzation_features(trainset):\n",
    "    features = []\n",
    "    \n",
    "    for img in trainset:\n",
    "        img = np.reshape(img, (28, 28))\n",
    "        cv_img = img.astype(np.unit8)\n",
    "        \n",
    "        img_b = binaryzation(cv_img)\n",
    "        feature.append(img_b)\n",
    "        \n",
    "    features = np.array(features)\n",
    "    features = np.reshape(features, (-1, 784))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class tree(object):\n",
    "    def __init__(self, node_type, Class = None, feature = None):\n",
    "        self.node_type = node_type\n",
    "        self.dict = {}\n",
    "        self.Class = Class\n",
    "        self.feature = feature\n",
    "    \n",
    "    def add_tree(self, val, tree):\n",
    "        self.dict[val] = tree\n",
    "        \n",
    "    def predict(self, features):\n",
    "        if self.node_type == 'leaf':\n",
    "            return self.Class\n",
    "    \n",
    "        tree = self.dict[features[self.feature]]\n",
    "        return tree.predict(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_ent(x):\n",
    "    x_value_list = set(x[i] for i in range(x.shape[0]))\n",
    "    ent = 0.0\n",
    "    \n",
    "    for x_value in x_value_list:\n",
    "        p = float(x[x == x_value].shape[0])/x.shape[0]\n",
    "        logp = np.log2(p)\n",
    "        ent -= p*logp\n",
    "    \n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_condition_ent(x, y):\n",
    "    x_value_list = set(x[i] for i in range(x.shape[0]))\n",
    "    ent = 0.0\n",
    "    for x_value in x_value_list:\n",
    "        sub_y = y[x == x_value]\n",
    "        temp_ent = calc_ent(sub_y)\n",
    "        ent += (float(sub_y.shape[0]) / y.shape[0]) * temp_ent\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_ent_grap(x, y):\n",
    "    base_ent = calc_ent(y)\n",
    "    condition_ent = calc_condition_ent(x, y)\n",
    "    ent_grap = base_ent - condition_ent\n",
    "    \n",
    "    return ent_grap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recurse_train(train_set, train_label, features = [i for i in range(784)], epsilon, total_class):\n",
    "    LEAF = 'leaf'\n",
    "    INTERNAL = 'internal'\n",
    "    \n",
    "    #步骤1-如果trainset中所有实例都属于同一类ck、\n",
    "    label_set = set(train_label)\n",
    "    if len(label_set) == 1:\n",
    "        return Tree(LEAF, Class = label_set.pop())\n",
    "    \n",
    "    #步骤2-如果features为空\n",
    "    (max_class, max_len) = max([(i, len(filter(lambda x:x==i, train_label))) for i in range(total_class)],\n",
    "                               key = lambda x:x[1])\n",
    "    \n",
    "    if len(features) == 0:\n",
    "        return tree(LEAF, Class = max_class)\n",
    "    \n",
    "    #步骤3-计算信息增益\n",
    "    max_feature = 0\n",
    "    max_gda = 0\n",
    "    \n",
    "    D = train_label\n",
    "    HD = calc_ent(D)\n",
    "    \n",
    "    for feature in features:\n",
    "        A = np.array(trian_set[:, feature].flat)\n",
    "        gda = HD - calc_condition_ent(A, D)\n",
    "        \n",
    "        if gda > max_gda:\n",
    "            max_gda, max_feture = fda, feature\n",
    "    \n",
    "    #步骤4-小于阈值\n",
    "    if max_gda < epsilon:\n",
    "        return Tree(LEAF, Class = max_class)\n",
    "    \n",
    "    #步骤5-构建非空子集\n",
    "    sub_features = filter(lambda x: x!=max_feature, features)\n",
    "    tree = Tree(INTERNAL, feature = max_feature)\n",
    "    \n",
    "    feature_col = np.array(train_set[:, max_feature].flat)\n",
    "    feature_value_list = set([feature_col[i] for i in range(feature_col.shape[0])])\n",
    "    \n",
    "    for feature_value in feature_value_list:\n",
    "        \n",
    "        index = []\n",
    "        for i in range(len(train_label)):\n",
    "            if train_set[i][max_feature] == feature_value:\n",
    "                index.append(i)\n",
    "        \n",
    "        sub_train_set = train_set[index]\n",
    "        sub_train_label = train_label[index]\n",
    "        \n",
    "        sub_tree = recurse_train(sub_train_set, sub_train_label, sub_features, epsilon)\n",
    "        tree.add_tree(feature_value, sub_tree)\n",
    "        \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(test_set, tree):\n",
    "    result = []\n",
    "    for features in test_set:\n",
    "        tmp_predict = tree.predict(features)\n",
    "        result.append(tmp_predict)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
